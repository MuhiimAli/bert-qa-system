Some weights of DistilBertForQA were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['distilbert.qa_outputs.bias', 'distilbert.qa_outputs.weight', 'distilbert.qa_type.bias', 'distilbert.qa_type.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Loss: 13.2778:   0%|          | 15/6966 [00:01<08:56, 12.96it/s]









































































































































































































































































Loss: 3.9772: 100%|██████████| 6966/6966 [08:52<00:00, 13.07it/s]




Loss: 2.9049, F1: 0.4223, EM: 0.6073:  92%|█████████▏| 401/436 [00:09<00:00, 43.03it/s]
Results:
Train Loss: 3.9772
Val Loss: 2.7629
Precision: 0.4469
Recall: 0.4094
F1: 0.4273
Loss: 2.7629, F1: 0.4273, EM: 0.6271: 100%|██████████| 436/436 [00:10<00:00, 42.26it/s]










































































































































































































































































Loss: 2.1756: 100%|██████████| 6966/6966 [08:54<00:00, 13.04it/s]




Loss: 3.2618, F1: 0.4891, EM: 0.6313:  91%|█████████ | 396/436 [00:09<00:00, 42.79it/s]
Results:
Train Loss: 2.1756
Val Loss: 3.1474
Precision: 0.4363
Recall: 0.5421
F1: 0.4835
Loss: 3.1474, F1: 0.4835, EM: 0.6477: 100%|██████████| 436/436 [00:10<00:00, 42.05it/s]












































































































































































































































































Loss: 1.3412: 100%|██████████| 6966/6966 [08:59<00:00, 12.92it/s]





Loss: 3.9867, F1: 0.5003, EM: 0.6512: 100%|██████████| 436/436 [00:10<00:00, 41.74it/s]
Results:
Train Loss: 1.3412
Val Loss: 3.9867
Precision: 0.4624
Recall: 0.5449
F1: 0.5003