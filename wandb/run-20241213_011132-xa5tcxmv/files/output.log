Some weights of DistilBertForQA were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['distilbert.qa_outputs.bias', 'distilbert.qa_outputs.weight', 'distilbert.qa_type.bias', 'distilbert.qa_type.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Loss: 13.0226:   0%|          | 15/6966 [00:01<09:03, 12.79it/s]












































































































































































































































































Loss: 3.9943: 100%|██████████| 6966/6966 [08:58<00:00, 12.92it/s]




Loss: 2.8411, F1: 0.4325, EM: 0.5806:  90%|████████▉ | 391/436 [00:09<00:01, 42.20it/s]
Results:
Train Loss: 3.9943
Val Loss: 2.7259
Precision: 0.3490
Recall: 0.5459
F1: 0.4258
Loss: 2.7259, F1: 0.4258, EM: 0.6001: 100%|██████████| 436/436 [00:10<00:00, 41.25it/s]













































































































































































































































































Loss: 2.1822: 100%|██████████| 6966/6966 [09:00<00:00, 12.90it/s]




Loss: 3.2861, F1: 0.5164, EM: 0.6224:  87%|████████▋ | 381/436 [00:09<00:01, 42.48it/s]
Results:
Train Loss: 2.1822
Val Loss: 3.1014
Precision: 0.4954
Recall: 0.5320
F1: 0.5130
Loss: 3.1014, F1: 0.5130, EM: 0.6500: 100%|██████████| 436/436 [00:10<00:00, 41.35it/s]













































































































































































































































































Loss: 1.3806: 100%|██████████| 6966/6966 [08:59<00:00, 12.90it/s]




Loss: 4.0137, F1: 0.5356, EM: 0.6391:  86%|████████▌ | 376/436 [00:09<00:01, 42.09it/s]
Results:
Train Loss: 1.3806
Val Loss: 3.7956
Precision: 0.5101
Recall: 0.5533

Loss: 3.7956, F1: 0.5308, EM: 0.6638: 100%|██████████| 436/436 [00:10<00:00, 41.16it/s]