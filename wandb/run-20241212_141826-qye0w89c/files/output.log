Some weights of DistilBertForQA were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['distilbert.qa_outputs.bias', 'distilbert.qa_outputs.weight', 'distilbert.qa_type.bias', 'distilbert.qa_type.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Loss: 13.0278:   0%|          | 15/6966 [00:01<08:54, 13.00it/s]











































































































































































































































































Loss: 3.9509: 100%|██████████| 6966/6966 [08:56<00:00, 12.99it/s]




Loss: 2.8030, F1: 0.4839, EM: 0.6223:  95%|█████████▌| 416/436 [00:09<00:00, 42.84it/s]
Results:
Train Loss: 3.9509
Val Loss: 2.7524
Precision: 0.4249
Recall: 0.5614
F1: 0.4837
Loss: 2.7524, F1: 0.4837, EM: 0.6294: 100%|██████████| 436/436 [00:10<00:00, 42.10it/s]











































































































































































































































































Loss: 2.1810: 100%|██████████| 6966/6966 [08:57<00:00, 12.95it/s]





Loss: 2.7266, F1: 0.4715, EM: 0.6380:  99%|█████████▉| 431/436 [00:10<00:00, 42.86it/s]
Results:
Train Loss: 2.1810
Val Loss: 2.7194
Precision: 0.4058
Recall: 0.5638
F1: 0.4720
Loss: 2.7194, F1: 0.4720, EM: 0.6397: 100%|██████████| 436/436 [00:10<00:00, 42.06it/s]











































































































































































































































































Loss: 1.3806: 100%|██████████| 6966/6966 [08:57<00:00, 12.95it/s]




Loss: 4.1150, F1: 0.5376, EM: 0.6233:  85%|████████▌ | 371/436 [00:08<00:01, 42.86it/s]
Results:
Train Loss: 1.3806
Val Loss: 3.8578
Precision: 0.5027
Recall: 0.5651

Loss: 3.8578, F1: 0.5321, EM: 0.6540: 100%|██████████| 436/436 [00:10<00:00, 42.11it/s]