Some weights of DistilBertForQA were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['distilbert.qa_outputs.bias', 'distilbert.qa_outputs.weight', 'distilbert.qa_type.bias', 'distilbert.qa_type.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Loss: 13.4840:   0%|          | 15/6966 [00:01<08:58, 12.91it/s]











































































































































































































































































Loss: 3.8755: 100%|██████████| 6966/6966 [08:58<00:00, 12.94it/s]





Loss: 3.1900, F1: 0.4292, EM: 0.6197:  98%|█████████▊| 426/436 [00:10<00:00, 42.25it/s]
Results:
Train Loss: 3.8755
Val Loss: 3.1381
Precision: 0.4444
Recall: 0.4174
F1: 0.4305
Loss: 3.1381, F1: 0.4305, EM: 0.6254: 100%|██████████| 436/436 [00:10<00:00, 41.63it/s]













































































































































































































































































Loss: 2.1307: 100%|██████████| 6966/6966 [09:00<00:00, 12.89it/s]




Loss: 3.1304, F1: 0.4957, EM: 0.6434:  94%|█████████▍| 411/436 [00:09<00:00, 42.58it/s]
Results:
Train Loss: 2.1307
Val Loss: 3.0785
Precision: 0.4777
Recall: 0.5148
F1: 0.4956
Loss: 3.0785, F1: 0.4956, EM: 0.6523: 100%|██████████| 436/436 [00:10<00:00, 41.63it/s]













































































































































































































































































Loss: 1.3209: 100%|██████████| 6966/6966 [09:00<00:00, 12.89it/s]




Loss: 4.1831, F1: 0.5027, EM: 0.6488:  92%|█████████▏| 401/436 [00:09<00:00, 42.50it/s]
Results:
Train Loss: 1.3209
Val Loss: 4.0765
Precision: 0.4880
Recall: 0.5048

Loss: 4.0765, F1: 0.4963, EM: 0.6609: 100%|██████████| 436/436 [00:10<00:00, 41.68it/s]