Some weights of DistilBertForQA were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['distilbert.qa_outputs.bias', 'distilbert.qa_outputs.weight', 'distilbert.qa_type.bias', 'distilbert.qa_type.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Loss: 13.3336:   0%|          | 15/6966 [00:01<08:57, 12.92it/s]











































































































































































































































































Loss: 3.9669: 100%|██████████| 6966/6966 [08:58<00:00, 12.95it/s]





Loss: 2.8300, F1: 0.4165, EM: 0.6007:  99%|█████████▉| 431/436 [00:10<00:00, 42.49it/s]
Results:
Train Loss: 3.9669
Val Loss: 2.8217
Precision: 0.3450
Recall: 0.5142
F1: 0.4129
Loss: 2.8217, F1: 0.4129, EM: 0.6013: 100%|██████████| 436/436 [00:10<00:00, 41.57it/s]











































































































































































































































































Loss: 2.2068: 100%|██████████| 6966/6966 [08:57<00:00, 12.97it/s]




Loss: 3.1801, F1: 0.5010, EM: 0.5964:  87%|████████▋ | 381/436 [00:09<00:01, 42.89it/s]
Results:
Train Loss: 2.2068
Val Loss: 3.0213
Precision: 0.4474
Recall: 0.5431
F1: 0.4906
Loss: 3.0213, F1: 0.4906, EM: 0.6208: 100%|██████████| 436/436 [00:10<00:00, 42.24it/s]










































































































































































































































































Loss: 1.3756: 100%|██████████| 6966/6966 [08:54<00:00, 13.03it/s]




Loss: 4.1340, F1: 0.5443, EM: 0.6131:  82%|████████▏ | 356/436 [00:08<00:01, 43.07it/s]
Results:
Train Loss: 1.3756
Val Loss: 3.7743
Precision: 0.5099
Recall: 0.5758

Loss: 3.7743, F1: 0.5409, EM: 0.6540: 100%|██████████| 436/436 [00:10<00:00, 42.13it/s]