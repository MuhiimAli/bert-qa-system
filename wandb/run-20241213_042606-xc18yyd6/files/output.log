Some weights of DistilBertForQA were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['distilbert.qa_outputs.bias', 'distilbert.qa_outputs.weight', 'distilbert.qa_type.bias', 'distilbert.qa_type.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Loss: 13.1078:   0%|          | 2/870 [00:01<08:10,  1.77it/s]























































































































































































































Loss: 4.4904: 100%|██████████| 870/870 [07:13<00:00,  2.01it/s]




Loss: 2.8903, F1: 0.3896, EM: 0.5827:  93%|█████████▎| 51/55 [00:08<00:00,  5.92it/s]
Results:
Train Loss: 4.4904
Val Loss: 2.7983
Precision: 0.3225
Recall: 0.4803
F1: 0.3859
Loss: 2.7983, F1: 0.3859, EM: 0.5967: 100%|██████████| 55/55 [00:09<00:00,  5.84it/s]
























































































































































































































Loss: 2.2934: 100%|██████████| 870/870 [07:14<00:00,  2.00it/s]




Loss: 2.5739, F1: 0.4520, EM: 0.6321:  96%|█████████▋| 53/55 [00:09<00:00,  5.91it/s]
Results:
Train Loss: 2.2934
Val Loss: 2.5161
Precision: 0.4036
Recall: 0.5187
F1: 0.4539
Loss: 2.5161, F1: 0.4539, EM: 0.6391: 100%|██████████| 55/55 [00:09<00:00,  5.84it/s]
























































































































































































































Loss: 1.6498: 100%|██████████| 870/870 [07:14<00:00,  2.00it/s]




Loss: 2.7082, F1: 0.4597, EM: 0.6286:  95%|█████████▍| 52/55 [00:08<00:00,  5.91it/s]
Results:
Train Loss: 1.6498
Val Loss: 2.6388
Precision: 0.4053
Recall: 0.5328

Loss: 2.6388, F1: 0.4604, EM: 0.6368: 100%|██████████| 55/55 [00:09<00:00,  5.83it/s]