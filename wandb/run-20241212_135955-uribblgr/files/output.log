Some weights of DistilBertForQA were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['distilbert.qa_outputs.bias', 'distilbert.qa_outputs.weight', 'distilbert.qa_type.bias', 'distilbert.qa_type.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Epoch 1/2








Loss: 12.8350:   4%|â–ˆâ–ˆâ–Ž                                                              | 31/870 [00:16<06:48,  2.05it/s][34m[1mwandb[39m[22m: Ctrl + C detected. Stopping sweep.