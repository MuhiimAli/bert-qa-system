Some weights of DistilBertForQA were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['distilbert.qa_outputs.bias', 'distilbert.qa_outputs.weight', 'distilbert.qa_type.bias', 'distilbert.qa_type.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Loss: 13.2204:   0%|          | 15/6966 [00:01<08:57, 12.94it/s]












































































































































































































































































Loss: 3.9649: 100%|██████████| 6966/6966 [08:58<00:00, 12.93it/s]




Loss: 2.9511, F1: 0.4430, EM: 0.5766:  93%|█████████▎| 406/436 [00:09<00:00, 42.54it/s]
Results:
Train Loss: 3.9649
Val Loss: 2.8953
Precision: 0.3706
Recall: 0.5539
F1: 0.4441
Loss: 2.8953, F1: 0.4441, EM: 0.5886: 100%|██████████| 436/436 [00:10<00:00, 41.82it/s]












































































































































































































































































Loss: 2.1428: 100%|██████████| 6966/6966 [08:59<00:00, 12.90it/s]





Loss: 3.0814, F1: 0.4974, EM: 0.6309:  92%|█████████▏| 401/436 [00:09<00:00, 42.65it/s]
Results:
Train Loss: 2.1428
Val Loss: 3.0007
Precision: 0.4719
Recall: 0.5167
F1: 0.4933
Loss: 3.0007, F1: 0.4933, EM: 0.6426: 100%|██████████| 436/436 [00:10<00:00, 41.59it/s]












































































































































































































































































Loss: 1.3297: 100%|██████████| 6966/6966 [08:59<00:00, 12.90it/s]





Loss: 3.8579, F1: 0.5158, EM: 0.6548:  98%|█████████▊| 426/436 [00:10<00:00, 42.53it/s]
Results:
Train Loss: 1.3297
Val Loss: 3.8050
Precision: 0.4726
Recall: 0.5703

Loss: 3.8050, F1: 0.5168, EM: 0.6592: 100%|██████████| 436/436 [00:10<00:00, 41.68it/s]